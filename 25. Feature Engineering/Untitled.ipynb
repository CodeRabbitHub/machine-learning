{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c96d5c-f34f-454c-b0a6-a1e92f1f02cb",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables:\n",
    "\n",
    "Categorical variables are those that represent categories or groups and don't have inherent numerical value. Encoding categorical variables is essential because many machine learning algorithms require numerical input. Here are the commonly used encoding techniques:\n",
    "\n",
    "#### 1. One-Hot Encoding:\n",
    "\n",
    "**Concept:**\n",
    "One-Hot Encoding converts categorical variables into binary vectors where each category is represented by a binary indicator (0 or 1).\n",
    "\n",
    "**Maths:**\n",
    "If a categorical variable has $ k $ unique categories, one-hot encoding creates $ k $ binary columns. For each sample, only one column will have a value of 1, indicating the presence of that category.\n",
    "\n",
    "**Example:**\n",
    "Suppose we have a categorical variable \"Color\" with three categories: Red, Blue, Green. After one-hot encoding:\n",
    "```\n",
    "| Color_Red | Color_Blue | Color_Green |\n",
    "|-----------|------------|-------------|\n",
    "|    1      |     0      |      0      |\n",
    "|    0      |     1      |      0      |\n",
    "|    0      |     0      |      1      |\n",
    "```\n",
    "\n",
    "**When to Use:**\n",
    "- When the categorical variable has no inherent order or hierarchy.\n",
    "- When the number of categories is not excessively large.\n",
    "\n",
    "**Why to Use:**\n",
    "- Ensures each category is treated equally.\n",
    "- Prevents numerical interpretation of ordinality.\n",
    "\n",
    "**Advantages:**\n",
    "- Maintains all information from the categorical variable.\n",
    "- Works well with most machine learning algorithms.\n",
    "\n",
    "**Disadvantages:**\n",
    "- Increases dimensionality, especially with high cardinality categorical variables.\n",
    "\n",
    "#### 2. Label Encoding:\n",
    "\n",
    "**Concept:**\n",
    "Label Encoding assigns a unique integer to each category, essentially converting categories into numerical labels.\n",
    "\n",
    "**Maths:**\n",
    "Assigning integers incrementally to categories. \n",
    "\n",
    "**Example:**\n",
    "Suppose we have a categorical variable \"Size\" with categories: Small, Medium, Large.\n",
    "```\n",
    "Small  -> 0\n",
    "Medium -> 1\n",
    "Large  -> 2\n",
    "```\n",
    "\n",
    "**When to Use:**\n",
    "- When the categorical variable has an inherent order or hierarchy.\n",
    "\n",
    "**Why to Use:**\n",
    "- Maintains ordinal information when it exists.\n",
    "\n",
    "**Advantages:**\n",
    "- Reduces dimensionality compared to one-hot encoding.\n",
    "- Preserves ordinal information.\n",
    "\n",
    "**Disadvantages:**\n",
    "- Can introduce unintended ordinality to categorical variables without natural order.\n",
    "\n",
    "#### 3. Ordinal Encoding:\n",
    "\n",
    "**Concept:**\n",
    "Ordinal Encoding assigns numerical values to categories based on their order or rank.\n",
    "\n",
    "**Maths:**\n",
    "Similar to Label Encoding, but the mapping is based on the order of categories.\n",
    "\n",
    "**Example:**\n",
    "Suppose we have a categorical variable \"Education\" with categories: High School, Bachelor's, Master's, PhD.\n",
    "```\n",
    "High School -> 1\n",
    "Bachelor's  -> 2\n",
    "Master's    -> 3\n",
    "PhD         -> 4\n",
    "```\n",
    "\n",
    "**When to Use:**\n",
    "- When the categorical variable has an inherent order or hierarchy, but the numerical difference between categories is not significant.\n",
    "\n",
    "**Why to Use:**\n",
    "- Preserves ordinal information.\n",
    "\n",
    "**Advantages:**\n",
    "- Reduces dimensionality compared to one-hot encoding.\n",
    "- Preserves ordinal information.\n",
    "\n",
    "**Disadvantages:**\n",
    "- Assumes equal spacing between categories which may not be true.\n",
    "\n",
    "#### 4. Target Encoding:\n",
    "\n",
    "**Concept:**\n",
    "Target Encoding (or Mean Encoding) replaces categories with the mean of the target variable for each category.\n",
    "\n",
    "**Maths:**\n",
    "For each category $ i $, replace it with the mean of the target variable $ y $ for that category.\n",
    "\n",
    "**Example:**\n",
    "Suppose we have a categorical variable \"City\" with different categories and a target variable \"Salary\".\n",
    "```\n",
    "|   City   | Salary |\n",
    "|----------|--------|\n",
    "|  London  |  5000  |\n",
    "|  Paris   |  6000  |\n",
    "|  London  |  4800  |\n",
    "|  Paris   |  5500  |\n",
    "```\n",
    "After target encoding:\n",
    "```\n",
    "|   City   | Salary |\n",
    "|----------|--------|\n",
    "|  London  |  4900  |\n",
    "|  Paris   |  5750  |\n",
    "|  London  |  4900  |\n",
    "|  Paris   |  5750  |\n",
    "```\n",
    "\n",
    "**When to Use:**\n",
    "- When one-hot encoding would create too many features.\n",
    "- When preserving the relationship between the category and the target variable is important.\n",
    "\n",
    "**Why to Use:**\n",
    "- Captures information about the target variable within the categorical variable.\n",
    "\n",
    "**Advantages:**\n",
    "- Reduces dimensionality compared to one-hot encoding.\n",
    "- Preserves relationship with target variable.\n",
    "\n",
    "**Disadvantages:**\n",
    "- Prone to overfitting, especially with small or noisy datasets.\n",
    "- Sensitive to outliers and imbalanced data.\n",
    "\n",
    "### Types of Target Encoding:\n",
    "\n",
    "- **Simple Mean Encoding:** Replace each category with the mean of the target variable.\n",
    "- **Smoothing Mean Encoding:** Combines the mean of the category with the overall mean to avoid overfitting.\n",
    "- **Leave-One-Out Encoding:** Similar to mean encoding but excludes the current sample's target value to avoid leakage.\n",
    "- **Expanding Mean Encoding:** Uses the expanding window mean of the target variable.\n",
    "\n",
    "These encoding techniques play a crucial role in preparing categorical variables for machine learning models, each with its own set of advantages and considerations depending on the nature of the data and the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5fac3-1808-47e4-9dc4-6139e46140f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
