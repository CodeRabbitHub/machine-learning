{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f31be33d-094e-4143-a2b7-533bfafa43e8",
   "metadata": {},
   "source": [
    "# Mean Shift\n",
    "\n",
    "Mean Shift is a clustering algorithm that operates by assigning each data point to a cluster based on the density of nearby points within the data space. Unlike traditional methods such as k-means, Mean Shift does not necessitate the upfront specification of the number of clusters, offering a more adaptive and data-driven approach to clustering analysis.\n",
    "\n",
    "Fundamentally, Mean Shift relies on the concept of identifying modes within the distribution function representing the dataset. These modes, akin to peaks in a landscape, signify regions of high density where data points congregate. The algorithm begins by conceptualizing the dataset as a probability density function, where areas of high concentration correspond to peaks and low-density regions represent valleys.\n",
    "\n",
    "The central principle of Mean Shift involves iteratively shifting each data point towards the nearest peak until convergence. This iterative process entails a local search procedure where each point is attracted to regions of higher density. As a consequence, data points gradually gravitate towards the mode most closely associated with them, effectively delineating clusters based on natural groupings within the data.\n",
    "\n",
    "In essence, Mean Shift harnesses the inherent structure of the data to autonomously identify clusters without the need for prior specification of cluster numbers. By iteratively adjusting the position of data points towards high-density regions, the algorithm efficiently captures the underlying distribution of the data and partitions it into distinct clusters.\n",
    "\n",
    "<center><img src=\"./imgs/meanshift.png\"/></center>\n",
    "\n",
    "The initial step of the mean-shift algorithm involves representing the dataset as a density distribution. This is achieved by leveraging the concept of Kernel Density Estimation (KDE), a technique employed to estimate the distribution of a dataset.\n",
    "\n",
    "In KDE, each data point is depicted as a probability distribution function centered at its location. These individual distributions are then summed to create an overall density estimate of the dataset. The resulting distribution portrays regions of high density, corresponding to clusters of data points.\n",
    "\n",
    "<center><img src=\"./imgs/finding-regions.png\"/></center>\n",
    "\n",
    "The accompanying diagram illustrates this process. The dots at the base of the figure denote the input data points provided by the user. Concurrently, the cone-shaped lines depict the estimated distribution of these data points. Notably, the peaks within this distribution, representing areas of high density, serve as indicators of distinct clusters within the dataset.\n",
    "\n",
    "By employing Kernel Density Estimation, the mean-shift algorithm effectively transforms raw data into a representation that facilitates the identification of natural groupings or clusters. This pivotal step lays the foundation for subsequent stages of the mean-shift clustering process.\n",
    "\n",
    "### Centroids and Windows\n",
    "- Initially, random data points are selected as centroids, serving as starting points for clustering.\n",
    "- Windows, defined as regions of influence around centroids, are created to guide the clustering process.\n",
    "- A window of a specified size (bandwidth) is drawn around each data point.\n",
    "\n",
    "### Mean Shift Vector\n",
    "- The mean shift vector determines the direction for shifting windows.\n",
    "- It represents the average shift of data points within a window and points towards regions of higher data density.\n",
    "- The mean of the data inside the window is computed.\n",
    "\n",
    "### Shifting the Windows\n",
    "- Windows are shifted iteratively towards the mean shift vector, bringing them closer to areas of high data density.\n",
    "- The center of the window is shifted to the mean.\n",
    "- After each shift, mean shift vectors are recalculated within updated windows.\n",
    "- This process continues until convergence, where windows reach final positions, indicating completion of clustering.\n",
    "\n",
    "Steps 2 and 3 are repeated until the data point reaches a peak, which will determine the cluster that it belongs to. The bandwidth value should be coherent with the distribution of the data points in the dataset. For example, for a dataset normalized between 0 and 1, the bandwidth value should be within that range, while for a dataset with all values between 1,000 and 2,000, it would make more sense to have a bandwidth between 100 and 500.\n",
    "\n",
    "### Advantages\n",
    "- Automatically chooses the number of clusters.\n",
    "- Automatically finds the shape of clusters.\n",
    "- Good performance with outliers.\n",
    "\n",
    "### Disadvantages\n",
    "- Performance diminishes in higher dimensions due to scalability issues.\n",
    "- High computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b4faf-d62e-4aa1-8dfd-1a24fda0214c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
