{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af3c2d2-efdb-43ee-9ac2-31afe5a3b482",
   "metadata": {},
   "source": [
    "## Independent Component Analysis (ICA)\n",
    "\n",
    "### Overview\n",
    "\n",
    "Independent Component Analysis (ICA) is a computational technique used to separate a multivariate signal into additive, independent non-Gaussian components. It is commonly used in signal processing and data analysis to decompose complex datasets into independent sources.\n",
    "\n",
    "### Mathematical Foundations\n",
    "\n",
    "#### 1. **Model Assumptions**\n",
    "\n",
    "Given a dataset $X$ with $n$ observations and $p$ features, ICA assumes the data can be expressed as a linear combination of statistically independent non-Gaussian sources.\n",
    "\n",
    "$$ X = AS $$\n",
    "\n",
    "where:\n",
    "- $X$ is the observed data matrix.\n",
    "- $A$ is the mixing matrix.\n",
    "- $S$ is the source matrix with independent components.\n",
    "\n",
    "The goal of ICA is to estimate both $A$ and $S$ such that the components in $S$ are as statistically independent as possible.\n",
    "\n",
    "#### 2. **Independence and Non-Gaussianity**\n",
    "\n",
    "ICA maximizes the statistical independence of the estimated components. Non-Gaussianity is a key criterion since the Central Limit Theorem implies that a mixture of non-Gaussian signals will tend to be more Gaussian than the original sources.\n",
    "\n",
    "#### 3. **Measures of Non-Gaussianity**\n",
    "\n",
    "Common measures of non-Gaussianity include:\n",
    "\n",
    "- **Kurtosis**: The fourth central moment of a distribution. Non-Gaussian signals have higher (super-Gaussian) or lower (sub-Gaussian) kurtosis than Gaussian signals.\n",
    "  \n",
    "  $$\n",
    "  \\text{Kurtosis}(y) = \\mathbb{E}[y^4] - 3(\\mathbb{E}[y^2])^2\n",
    "  $$\n",
    "\n",
    "- **Negentropy**: A measure of the distance from Gaussianity based on information theory.\n",
    "  \n",
    "  $$\n",
    "  J(y) = H(y_{\\text{Gaussian}}) - H(y)\n",
    "  $$\n",
    "\n",
    "  where $ H(y) $ is the differential entropy of $ y $.\n",
    "\n",
    "#### 4. **FastICA Algorithm**\n",
    "\n",
    "The FastICA algorithm is a popular method to perform ICA. It involves the following steps:\n",
    "\n",
    "1. **Centering**: Subtract the mean of each feature to center the data.\n",
    "   \n",
    "   $$\n",
    "   X = X - \\mathbb{E}[X]\n",
    "   $$\n",
    "\n",
    "2. **Whitening**: Transform the data such that its components are uncorrelated and have unit variance. This can be done using eigenvalue decomposition (EVD) or singular value decomposition (SVD).\n",
    "   \n",
    "   $$\n",
    "   X_{\\text{whitened}} = E D^{-1/2} E^T X\n",
    "   $$\n",
    "\n",
    "   where $ E $ is the matrix of eigenvectors and $ D $ is the diagonal matrix of eigenvalues.\n",
    "\n",
    "3. **Iterative Optimization**: Use an iterative method to find the unmixing matrix $ W $ that maximizes non-Gaussianity.\n",
    "   \n",
    "   $$\n",
    "   W \\leftarrow \\mathbb{E}\\left[ Xg(W^TX) \\right] - \\mathbb{E}\\left[ g'(W^TX) \\right] W\n",
    "   $$\n",
    "\n",
    "   where $ g $ is a non-linear function (e.g., $ g(y) = \\tanh(y) $) and $ g' $ is its derivative.\n",
    "\n",
    "4. **Normalization**: Normalize the rows of $ W $ to ensure they remain unit vectors.\n",
    "\n",
    "5. **Update and Convergence**: Repeat the optimization until convergence.\n",
    "\n",
    "### Example\n",
    "\n",
    "Consider a dataset with two observed signals that are linear mixtures of two independent source signals. ICA aims to recover the original source signals.\n",
    "\n",
    "1. **Centering and Whitening**\n",
    "\n",
    "   Center the data by subtracting the mean and whiten the data to make the components uncorrelated.\n",
    "\n",
    "2. **Iterative Optimization**\n",
    "\n",
    "   Use the FastICA algorithm to iteratively adjust $ W $ to maximize the independence of the estimated sources.\n",
    "\n",
    "3. **Recovered Signals**\n",
    "\n",
    "   The resulting matrix $ S = W X $ contains the estimated independent components.\n",
    "\n",
    "### When to Use ICA\n",
    "\n",
    "- **Signal separation**: When the goal is to separate mixed signals into independent sources (e.g., separating audio signals from different speakers).\n",
    "- **Feature extraction**: To identify independent features in data for further analysis or modeling.\n",
    "- **Anomaly detection**: To detect independent and non-Gaussian components that may represent anomalies.\n",
    "\n",
    "### How to Use ICA\n",
    "\n",
    "1. **Preprocess the data**: Center and whiten the data.\n",
    "2. **Choose the ICA algorithm**: FastICA is a commonly used algorithm.\n",
    "3. **Determine the number of components**: Set the number of independent components to extract.\n",
    "4. **Run the ICA algorithm**: Apply the algorithm to the preprocessed data.\n",
    "5. **Analyze the components**: Examine the extracted independent components.\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- **Recovers independent sources**: Effectively separates mixed signals into independent components.\n",
    "- **Non-Gaussianity**: Works well for signals that are non-Gaussian.\n",
    "- **Versatility**: Applicable in various fields such as signal processing, image analysis, and neuroscience.\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "- **Sensitivity to assumptions**: Assumes that the sources are statistically independent and non-Gaussian, which may not always hold.\n",
    "- **Order of components**: The order of the extracted components is not guaranteed and may require interpretation.\n",
    "- **Scalability**: Computationally intensive for large datasets.\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "1. **Statistical independence**: The source signals are statistically independent.\n",
    "2. **Non-Gaussianity**: At most one source signal can be Gaussian.\n",
    "3. **Linear mixing**: The observed signals are linear mixtures of the source signals.\n",
    "4. **No noise**: Assumes that the observed signals are noise-free.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Independent Component Analysis (ICA) is a powerful technique for decomposing a multivariate signal into independent components. By maximizing non-Gaussianity and statistical independence, ICA effectively separates mixed signals, making it a valuable tool in various applications. While it relies on specific assumptions, ICA's ability to uncover hidden independent sources makes it a widely used method in signal processing and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6d4ee-cd2d-4a13-a767-f34d7daaadf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
