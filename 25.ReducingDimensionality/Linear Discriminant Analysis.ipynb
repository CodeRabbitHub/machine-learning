{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "198a908f-639c-482f-aacd-e6ebd118f30b",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis (LDA)\n",
    "\n",
    "### Overview\n",
    "\n",
    "Linear Discriminant Analysis (LDA) is a supervised learning algorithm used for classification and dimensionality reduction. It finds the linear combination of features that best separates two or more classes of data.\n",
    "\n",
    "### Mathematical Foundations\n",
    "\n",
    "#### 1. **Data Representation**\n",
    "Given a dataset $X$ with $n$ samples and $p$ features, and a target vector $y$ with $k$ distinct classes.\n",
    "\n",
    "#### 2. **Class-wise Mean Vectors**\n",
    "Compute the mean vector for each class $ \\mu_i $ where $ i $ represents the class index.\n",
    "\n",
    "$$ \\mu_i = \\frac{1}{n_i} \\sum_{x \\in X_i} x $$\n",
    "where $n_i$ is the number of samples in class $i$ and $X_i$ is the set of samples in class $i$.\n",
    "\n",
    "#### 3. **Overall Mean Vector**\n",
    "Compute the overall mean vector $\\mu$ for the entire dataset.\n",
    "\n",
    "$$ \\mu = \\frac{1}{n} \\sum_{i=1}^k \\sum_{x \\in X_i} x $$\n",
    "\n",
    "#### 4. **Scatter Matrices**\n",
    "- **Within-class scatter matrix $S_W$**: Measures the scatter (variance) within each class.\n",
    "\n",
    "$$ S_W = \\sum_{i=1}^k \\sum_{x \\in X_i} (x - \\mu_i)(x - \\mu_i)^T $$\n",
    "\n",
    "- **Between-class scatter matrix $S_B$**: Measures the scatter between the class means.\n",
    "\n",
    "$$ S_B = \\sum_{i=1}^k n_i (\\mu_i - \\mu)(\\mu_i - \\mu)^T $$\n",
    "\n",
    "#### 5. **Eigenvalue Problem**\n",
    "Solve the generalized eigenvalue problem to find the linear discriminants:\n",
    "\n",
    "$$ S_W^{-1} S_B v = \\lambda v $$\n",
    "\n",
    "Here, $ \\lambda $ represents the eigenvalues and $ v $ represents the eigenvectors (linear discriminants).\n",
    "\n",
    "#### 6. **Selecting Linear Discriminants**\n",
    "Sort the eigenvalues in descending order and select the top $ k-1 $ eigenvectors to form the transformation matrix $ W $.\n",
    "\n",
    "#### 7. **Projecting Data**\n",
    "Project the original data onto the new subspace:\n",
    "\n",
    "$$ X_{LDA} = X W $$\n",
    "\n",
    "### Example\n",
    "\n",
    "Suppose we have a dataset with two features: length and width, and two classes: A and B.\n",
    "\n",
    "1. **Class-wise Mean Vectors**\n",
    "\n",
    "    - Class A: $ \\mu_A = [1, 2]^T $\n",
    "    - Class B: $ \\mu_B = [3, 4]^T $\n",
    "\n",
    "2. **Overall Mean Vector**\n",
    "\n",
    "    $$ \\mu = [2, 3]^T $$\n",
    "\n",
    "3. **Scatter Matrices**\n",
    "\n",
    "    - Within-class scatter matrix $ S_W $:\n",
    "\n",
    "    $$\n",
    "    S_W = \\begin{bmatrix}\n",
    "    0.5 & 0 \\\\\n",
    "    0 & 0.5\n",
    "    \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "    - Between-class scatter matrix $ S_B $:\n",
    "\n",
    "    $$\n",
    "    S_B = \\begin{bmatrix}\n",
    "    2 & 2 \\\\\n",
    "    2 & 2\n",
    "    \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "4. **Eigenvalue Problem**\n",
    "\n",
    "    Solve $ S_W^{-1} S_B v = \\lambda v $ to get eigenvalues and eigenvectors.\n",
    "\n",
    "5. **Selecting Linear Discriminants**\n",
    "\n",
    "    Select the eigenvector corresponding to the largest eigenvalue.\n",
    "\n",
    "6. **Projecting Data**\n",
    "\n",
    "    Project data onto the selected linear discriminant.\n",
    "\n",
    "### When to Use LDA\n",
    "\n",
    "- **Classification tasks**: LDA is primarily used for classification when class labels are available.\n",
    "- **Dimensionality reduction**: LDA reduces dimensions while preserving class separability, making it useful for visualization and preprocessing.\n",
    "\n",
    "### How to Use LDA\n",
    "\n",
    "1. **Compute class-wise and overall mean vectors**.\n",
    "2. **Calculate within-class and between-class scatter matrices**.\n",
    "3. **Solve the generalized eigenvalue problem**.\n",
    "4. **Select the top $ k-1 $ eigenvectors**.\n",
    "5. **Project the original data onto the new subspace**.\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- **Improves class separability**: Maximizes the distance between class means while minimizing the spread within each class.\n",
    "- **Effective for linear boundaries**: Works well when classes are linearly separable.\n",
    "- **Reduces dimensionality**: Reduces feature space to $ k-1 $ dimensions for $ k $ classes, useful for visualization.\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "- **Assumes normality**: Assumes that features are normally distributed within each class.\n",
    "- **Sensitive to outliers**: Outliers can affect the mean and covariance estimates, impacting performance.\n",
    "- **Requires linear separability**: May not perform well if classes are not linearly separable.\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "1. **Normal distribution**: Assumes that features are normally distributed within each class.\n",
    "2. **Equal covariance matrices**: Assumes that all classes share the same covariance matrix.\n",
    "3. **Linearity**: Assumes linear boundaries between classes.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "LDA is a powerful technique for both classification and dimensionality reduction in supervised learning. By maximizing the ratio of between-class variance to within-class variance, LDA ensures maximum class separability in the projected subspace. While it has certain assumptions and limitations, it remains a widely used and effective method in various applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60143ad-6505-41bc-b345-7f0a730374fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
