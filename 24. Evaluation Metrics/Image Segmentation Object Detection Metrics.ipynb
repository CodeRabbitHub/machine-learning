{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac96468c-1145-4ab4-9da1-982c8cec4eaf",
   "metadata": {},
   "source": [
    "\n",
    "### Image Segmentation Metrics\n",
    "\n",
    "#### 1. Intersection over Union (IoU)\n",
    "- **Definition**: Intersection over Union measures the overlap between the predicted segmentation mask and the ground truth mask by calculating the ratio of the intersection area to the union area.\n",
    "  \n",
    "  $$\n",
    "  \\text{IoU} = \\frac{\\text{Area of Intersection}}{\\text{Area of Union}}\n",
    "  $$\n",
    "\n",
    "- **When to Use**: IoU is commonly used in image segmentation tasks to evaluate the accuracy of object localization.\n",
    "- **Advantages**: Provides a simple and intuitive measure of segmentation accuracy.\n",
    "- **Disadvantages**: Does not account for true positives outside the intersection area.\n",
    "\n",
    "#### 2. Dice Coefficient\n",
    "- **Definition**: Dice Coefficient is another measure of overlap between two segmentation masks, calculated as twice the intersection area divided by the sum of areas of the predicted and ground truth masks.\n",
    "  \n",
    "  $$\n",
    "  \\text{Dice Coefficient} = \\frac{2 \\times \\text{Area of Intersection}}{\\text{Area of Predicted Mask} + \\text{Area of Ground Truth Mask}}\n",
    "  $$\n",
    "\n",
    "- **When to Use**: Dice Coefficient is commonly used in medical image segmentation and other fields where precise overlap measurement is crucial.\n",
    "- **Advantages**: Sensitive to small variations in segmentation accuracy.\n",
    "- **Disadvantages**: May be less interpretable compared to IoU.\n",
    "\n",
    "#### 3. Pixel Accuracy\n",
    "- **Definition**: Pixel Accuracy measures the proportion of correctly classified pixels in the segmentation output.\n",
    "  \n",
    "  $$\n",
    "  \\text{Pixel Accuracy} = \\frac{\\text{Number of Correctly Classified Pixels}}{\\text{Total Number of Pixels}}\n",
    "  $$\n",
    "\n",
    "- **When to Use**: Pixel Accuracy provides a simple measure of segmentation performance, suitable for binary segmentation tasks.\n",
    "- **Advantages**: Easy to compute and interpret.\n",
    "- **Disadvantages**: Ignores class imbalance and pixel-wise misclassifications.\n",
    "\n",
    "#### 4. Mean Pixel Accuracy\n",
    "- **Definition**: Mean Pixel Accuracy calculates the average pixel accuracy across all classes in a segmentation task.\n",
    "\n",
    "  $$\n",
    "  \\text{Mean Pixel Accuracy} = \\frac{\\sum_{i=1}^{C} \\text{Pixel Accuracy}_i}{C}\n",
    "  $$\n",
    "  \n",
    "- **When to Use**: Mean Pixel Accuracy is used to assess segmentation performance when dealing with multi-class segmentation problems.\n",
    "- **Advantages**: Provides a class-balanced measure of segmentation accuracy.\n",
    "- **Disadvantages**: May mask inaccuracies in specific classes.\n",
    "\n",
    "### Object Detection Metrics\n",
    "\n",
    "#### 5. Mean Average Precision (mAP)\n",
    "- **Definition**: Mean Average Precision calculates the average precision over all classes and then averages those average precisions.\n",
    "\n",
    "  $$\n",
    "  \\text{mAP} = \\frac{1}{N} \\sum_{i=1}^{N} \\text{AP}_i\n",
    "  $$\n",
    "  \n",
    "- **When to Use**: mAP is commonly used to evaluate the performance of object detection models across multiple classes.\n",
    "- **Advantages**: Comprehensive metric that considers both precision and recall across classes.\n",
    "- **Disadvantages**: Sensitive to the choice of confidence thresholds.\n",
    "\n",
    "#### 6. Average Precision (AP)\n",
    "- **Definition**: Average Precision measures the area under the precision-recall curve for a specific class.\n",
    "\n",
    "  $$\n",
    "  \\text{AP} = \\sum_{k=1}^{n} (R_k - R_{k-1}) \\cdot P_k\n",
    "  $$\n",
    "  \n",
    "- **When to Use**: AP is used to assess the precision-recall trade-off for individual classes in object detection tasks.\n",
    "- **Advantages**: Provides a detailed evaluation of detection performance for each class.\n",
    "- **Disadvantages**: Requires a confidence threshold for object detection.\n",
    "\n",
    "#### 7. Precision-Recall Curves\n",
    "- **Definition**: Precision-Recall Curves plot the precision against recall for different confidence thresholds.\n",
    "\n",
    "  $$\n",
    "  \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n",
    "  $$\n",
    "  \n",
    "  $$\n",
    "  \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n",
    "  $$\n",
    "\n",
    "These formulas play a crucial role in evaluating classification models, providing insights into their ability to correctly identify positive instances and avoid false positives. Let me know if you need further clarification or additional information!\n",
    "  \n",
    "- **When to Use**: Precision-Recall Curves provide insights into the trade-off between precision and recall for different detection thresholds.\n",
    "- **Advantages**: Visual representation of model performance across various confidence levels.\n",
    "- **Disadvantages**: May require careful interpretation, especially in imbalanced datasets.\n",
    "\n",
    "#### 8. Recall at k (R@k)\n",
    "- **Definition**: Recall at k measures the proportion of ground truth objects that are detected in the top k predictions.\n",
    "\n",
    "  $$\n",
    "  \\text{R@k} = \\frac{\\text{Number of True Positives in top k predictions}}{\\text{Total Number of Ground Truth Objects}}\n",
    "  $$\n",
    "  \n",
    "- **When to Use**: R@k is used to assess object detection performance when considering only the top k predictions.\n",
    "- **Advantages**: Provides insights into model performance at different recall levels.\n",
    "- **Disadvantages**: Performance evaluation is limited to a specific number of predictions.\n",
    "\n",
    "These metrics are essential for evaluating the performance of image segmentation and object detection models in various applications, providing insights into the accuracy, robustness, and generalization capabilities of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a70ae-d465-4229-b647-f804cb2f5b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
